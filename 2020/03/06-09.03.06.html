<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8" /><meta name="viewport" content="width=device-width, initial-scale=1.0"><link rel="stylesheet" href="../../css.css"/ ></head><body>

<div class="content"><h1>Sufficient technology</h1>
<p>Let’s hypothesise sufficient brain scans. As far as I know, we don't have better than <em>either</em> very low resolution full-brain imaging (millions of synapses per voxel), <em>or</em> very limited high resolution imaging (thousands of synapses total), at least not for living brains. Let's just pretend for the sake of argument that we have synapse-resolution full-brain scans of living subjects.</p>

<p>What are the implications?</p>

<ul><li>Is a backup of your mind protected by the right to avoid self-incrimination? What about the minds of your pets?</li>
<li>Does a backup need to be punished (e.g. prison) if the person it is made from is punished? What if the offence occurred after the backup was made?</li>
<li>If the mind state is running rather than offline cold-storage, how many votes do all the copies get? What if they’re allowed to diverge? Which of them is allowed to access the bank accounts or other assets of the original? Is the original entitled to money earned by the copies?</li>
<li>If you memorise something and then get backed up, is that copyright infringement?
</li>
<li>If a mind can run on silicon for less than the cost of food to keep a human healthy, can anyone other than the foremost mind in their respective field ever be employed?
</li>
<li>If someone is backed up then the original is killed by someone who knows the person was backed up, is that murder, or is it the equivalent of a serious assault that causes a small duration of amnesia?</li></ul>

<hr />

<p><a href="https://kitsunesoftware.wordpress.com/2020/03/06/sufficient-technology/">Original post: https://kitsunesoftware.wordpress.com/2020/03/06/sufficient-technology/</a></p>

<p>Original post timestamp: Fri, 06 Mar 2020 09:03:06 +0000</a></p>

<p>Tags: <a href='https://benwheatley.github.io/blog/tags/AI'>AI</a>, <a href='https://benwheatley.github.io/blog/tags/brain science'>brain science</a>, <a href='https://benwheatley.github.io/blog/tags/brains'>brains</a>, <a href='https://benwheatley.github.io/blog/tags/consciousness'>consciousness</a>, <a href='https://benwheatley.github.io/blog/tags/ethics'>ethics</a>, <a href='https://benwheatley.github.io/blog/tags/futurism'>futurism</a>, <a href='https://benwheatley.github.io/blog/tags/mind uploading'>mind uploading</a>, <a href='https://benwheatley.github.io/blog/tags/morality'>morality</a>, <a href='https://benwheatley.github.io/blog/tags/Science'>Science</a>, <a href='https://benwheatley.github.io/blog/tags/Science Fiction'>Science Fiction</a>, <a href='https://benwheatley.github.io/blog/tags/Technological Singularity'>Technological Singularity</a>, <a href='https://benwheatley.github.io/blog/tags/theory of mind'>theory of mind</a>, <a href='https://benwheatley.github.io/blog/tags/wild speculation'>wild speculation</a></p>

<p>Categories: <a href='https://benwheatley.github.io/blog/categories/Futurology'>Futurology</a>, <a href='https://benwheatley.github.io/blog/categories/Minds'>Minds</a>, <a href='https://benwheatley.github.io/blog/categories/Philosophy'>Philosophy</a>, <a href='https://benwheatley.github.io/blog/categories/Politics'>Politics</a>, <a href='https://benwheatley.github.io/blog/categories/SciFi'>SciFi</a>, <a href='https://benwheatley.github.io/blog/categories/Technology'>Technology</a>, <a href='https://benwheatley.github.io/blog/categories/Transhumanism'>Transhumanism</a></p>
</div>

</body>
</html>
