<h1>Homeopathic solutions to the Fermi paradox</h1>
<strong>Homeopathy</strong>: for those who have never learned the details, claims that the potency of a treatment can be increased by repeatedly diluting it. There are many scales — <a href="https://en.wikipedia.org/wiki/Homeopathic_dilutions" target="_blank" rel="noopener">the C-scale is "how many times has this been diluted by a factor of 100", the X-scale "…by a factor of 10"</a>. I'd say "clearly nonsense", but I fell for it when I was a teenager.

<strong>Fermi paradox</strong>: there are so many stars in the observable universe — tens of <a href="https://en.wikipedia.org/wiki/Names_of_large_numbers" target="_blank" rel="noopener">sextillions (short scale)</a> — that even fairly pessimistic assumptions imply we should be surrounded by noisy aliens… so why can't we see any?

<p>One of the most common resolutions to the Fermi paradox is that there are one or more <a href="https://en.wikipedia.org/wiki/Great_Filter" target="_blank" rel="noopener">"great filters"</a> which make it entirely unlikely that any of those stars have produced intergalactic expansionist civilisations. There are good reasons to <a href="https://www.youtube.com/watch?v=zQTfuI-9jIo" target="_blank" rel="noopener">expect direct intergalactic expansion rather than starting with 'mere' interstellar expansion</a>, and (rather more surprisingly) good reasons to think we're within spitting distance of the technology required, but that only makes the non-technological problems all the more severe. There are a lot of unknowns here, obviously we've only got ourselves as an example, so the space between "where we are now" and "owning the universe" is filled entirely with <a href="https://en.wikipedia.org/wiki/Gnomes_(South_Park)#Plot" target="_blank" rel="noopener">underpants gnomes</a>, and that's where homeopathy fits in, in two separate ways.</p>

<p>First, as a categorical example. Homeopathy represents an archaic way of thinking, yet it's very popular. It's <em>simple</em>, it's <em>friendly</em>, it is a <a href="https://www.youtube.com/watch?v=rE3j_RHkqJc" target="_blank" rel="noopener">viral meme</a>. There are many of these, some of them are quite destructive, and while it's nice to think nature is in a balance — especially when we're thinking of something we're really proud of such as our own minds — the truth is nature (including humans) <a href="https://en.wikipedia.org/wiki/Overshoot_%28population%29" target="_blank" rel="noopener">often</a> goes <a href="https://en.wikipedia.org/wiki/Societal_collapse" target="_blank" rel="noopener">off</a> the <a href="https://en.wikipedia.org/wiki/Easter_Island" target="_blank" rel="noopener">deep</a> end and <a href="https://en.wikipedia.org/wiki/Great_Oxygenation_Event" target="_blank" rel="noopener">only sometimes</a> recovers. It's very easy for me to believe that an anti-rational meme such as homeopathy can either destroy a civilisation entirely, or prevent it developing into a proper space-faring civilisation.</p>

<p>Second, as an analogy. Dilution. It's not the first dilution of a homeopathic preparation which removes all atoms of active ingredients from the result, but the <em>repeated</em> dilution. If there are, say, twenty things which have an independent 50% chance of holding back or wiping out a civilisation out before it can set up a colony — AI; bioweapons; cyber-warfare; global climate change (doesn't matter if artificial warming or natural ice age); cascade agricultural collapse; mineral resource exhaustion; grey goo; global thermonuclear war; cosmic threats collectively from <a href="https://en.wikipedia.org/wiki/Solar_storm_of_1859" target="_blank" rel="noopener">noisy stars whose CMEs make electricity impractical</a> to <a href="https://en.wikipedia.org/wiki/Impact_event" target="_blank" rel="noopener">asteroids</a> and <a href="https://en.wikipedia.org/wiki/Gamma-ray_burst" target="_blank" rel="noopener">gamma ray bursts</a>; anti-intellectualism movements, whether <a href="https://en.wikipedia.org/wiki/Khmer_Rouge" target="_blank" rel="noopener">deliberate</a> or <a href="https://en.wikipedia.org/wiki/Dysgenics#Fertility_and_intelligence" target="_blank" rel="noopener">not</a>; feedback between cheap genetic engineering and <a href="https://en.wikipedia.org/wiki/Supernormal_stimulus" target="_blank" rel="noopener">genetically-defined super-stimulus</a> making all the citizens a <a href="https://en.wikipedia.org/wiki/Monoculture_(computer_science)" target="_blank" rel="noopener">biologically vulnerable monoculture</a> … — twenty items each with a 50% chance adds up to million-to-one odds (million-ish, but if you care about the difference you're taking the wrong lesson from this).</p>

<p>Yes, one-million-to-one is almost irrelevant compared to ten sextillion. Odds of (100e9)^2-to-one would require 73 such events, not 20, but this <em>combines</em> with the previous Fermi estimates, it doesn't <em>replace</em> them. 20 such events reduces the overall problem by a factor of a million, no matter what your previous estimate was, and both 20 events and 50% chances are just round numbers, not a real ones. Unfortunately, we don't know how many small-filters we might face: as the <a href="https://en.wikipedia.org/wiki/Great_Recession" target="_blank" rel="noopener">Great Recession</a> was starting, someone said that no two recessions are the same because we learn from all our mistakes and so each mistake has to be a new one. Sadly it's worse even than that, as humanity as a whole <a href="https://en.wikipedia.org/wiki/Hyperinflation#Notable_hyperinflationary_episodes" target="_blank" rel="noopener">does repeat even its economic mistakes</a>, so even if we weren't re-rolling some of our previously-successful dice because we keep thinking "<a href="https://duckduckgo.com/?q=they+need+us+more+than+we+need+them&amp;ia=web" target="_blank" rel="noopener">we're too big to fail</a>", <a href="https://en.wikipedia.org/wiki/Black_swan_theory" target="_blank" rel="noopener">humans don't know</a> <a href="https://en.wikipedia.org/wiki/I_know_that_I_know_nothing" target="_blank" rel="noopener">all the</a> <a href="https://en.wikipedia.org/wiki/There_are_known_knowns" target="_blank" rel="noopener">ways we can</a> <a href="https://en.wikipedia.org/wiki/Excession#Outside_Context_Problem" target="_blank" rel="noopener">fail to survive</a>.</p>

<p>The Great Filter doesn't have to be <a href="https://duckduckgo.com/?q=outside+context+problem&amp;ia=web" target="_blank" rel="noopener">something that civilisations encounter exactly once and in much the same way a sentence encounters a full stop</a> — it can be the death of a thousand paper-cuts.</p>

<p>If we do finally reach the stars, we may find the universe is much more interesting than it currently seems. Instead of Vulcans and warp drive, we might find hippy space-elves communing with their trees via mind-warping drugs… and if we don't, instead of wiping ourselves out, we might become the hippy space-elves that <a href="http://en.wikifur.com/wiki/Sam_Starfall" target="_blank" rel="noopener">some sentient octopus</a> discovers while going boldly where no sentient octopus has gone before.</p>

<p><a href="https://kitsunesoftware.wordpress.com/2019/01/07/homeopathic-solutions-to-the-fermi-paradox/">Original post: https://kitsunesoftware.wordpress.com/2019/01/07/homeopathic-solutions-to-the-fermi-paradox/</a></p>

<p>Original post timestamp: Mon, 07 Jan 2019 21:22:07 +0000</a></p>

<p>Tags: <a href='https://benwheatley.github.io/blog/tags/aliens'>aliens</a>, <a href='https://benwheatley.github.io/blog/tags/civilisation'>civilisation</a>, <a href='https://benwheatley.github.io/blog/tags/Fermi paradox'>Fermi paradox</a>, <a href='https://benwheatley.github.io/blog/tags/links'>links</a>, <a href='https://benwheatley.github.io/blog/tags/meme'>meme</a>, <a href='https://benwheatley.github.io/blog/tags/space'>space</a></p>

<p>Categories: <a href='https://benwheatley.github.io/blog/categories/Science'>Science</a></p>
